#!/usr/bin/env python3

import numpy as np
import argparse
import csv
from babyai.algos.imitation import ImitationLearning
import babyai.utils as utils
from babyai.scripts.evaluate import evaluate
import torch
import torch.nn.functional as F
import copy
import gym
import babyai

parser = argparse.ArgumentParser()
parser.add_argument("--env", required=True,
                    help="name of the environment to train on (REQUIRED)")
parser.add_argument("--demos-origin", required=True,
                    help="origin of the demonstrations: human | agent (REQUIRED)")
parser.add_argument("--lr", type=float, default=7e-4,
                    help="learning rate (default: 7e-4)")
parser.add_argument("--entropy-coef", type=float, default=0.2,
                    help="entropy term coefficient (default: 0.2)")
parser.add_argument("--recurrence", type=int, default=1,
                    help="number of timesteps gradient is backpropagated (default: 1)")
parser.add_argument("--optim-eps", type=float, default=1e-5,
                    help="Adam optimizer epsilon (default: 1e-5)")
parser.add_argument("--batch-size", type=int, default=50,
                    help="batch size (In case of memory, the batch size is the number of demos, otherwise, it is the number of frames)(default: 50)")
parser.add_argument("--no-instr", action="store_true", default=False,
                    help="don't use instructions in the model")
parser.add_argument("--no-mem", action="store_true", default=False,
                    help="don't use memory in the model")
parser.add_argument("--arch", default='cnn1',
                    help="image embedding architecture")
parser.add_argument("--discount", type=float, default=0.99,
                    help="discount factor (default: 0.99)")
parser.add_argument("--value-loss-coef", type=float, default=0,
                    help="value loss term coefficient (default: 0)")
parser.add_argument("--validation-interval", type=int, default=20,
                    help="number of epochs between two validation checks (default: 20)")
parser.add_argument("--episodes-to-add", type=int, default=100,
                    help="number of episodes to add each time  (default: 100)")
parser.add_argument("--patience", type=int, default=3,
                    help="patience for early stopping (default: 3)")
parser.add_argument("--val-seed", type=int, default=0,
                    help="seed for environment used for validation (default: 0)")
parser.add_argument("--start-demo", type=int, default=50,
                    help="the starting number of demonstrations (default: 50)")
parser.add_argument("--model", default=None,
                    help="name of the model (default: ENV_ORIGIN_il)")
parser.add_argument("--seed", type=int, default=1,
                    help="random seed (default: 1)")
parser.add_argument("--val-episodes", type=int, default=1000,
                    help="number of episodes used for validation (default: 1000)")
parser.add_argument("--tb", action="store_true", default=False,
                    help="log into Tensorboard")
parser.add_argument("--instr-arch", default="gru",
                    help="arch to encode instructions, possible values: gru, conv, bow (default: gru)")
parser.add_argument("--expert-model", default=None,
                    help="model to be used for Dagger sataset generation")
parser.add_argument("--max-demo", default=5000,
                    help="the maximum number of demonstrations allowed (default: 5000)")
parser.add_argument("--dagger", action="store_true", default=False,
                    help="add new demos through dagger method (default: False")

# Add new demonstrations based on mean reward of the baby agent
def add_new_demos(args,il_learn):
   model = args.model
   env = gym.make(args.env)
   env.seed(args.seed)
   utils.seed(args.seed)
   args.deterministic = True

   agent = utils.load_agent(args, env)
   logs = evaluate(agent, env, len(il_learn.train_demos))
   returns = np.array(logs["return_per_episode"])
   observations = logs["observations_per_episode"]
   new_inds = np.argsort(returns)[:args.episodes_to_add]

   new_demos  = []

   if not args.dagger:
    for index in new_inds:
      new_demos.append(il_learn.train_demos[index])
    return new_demos

   # Loading an expert agent to get action for the trajectory generated by baby agent
   args.model = args.expert_model
   expert_agent = utils.load_agent(args, env)

   for index in new_inds:

    demo = []
    if len(observations[index]) > 2 * optimal_steps:
        demo = il_learn.train_demos[index]
    else:
        for i in range(min(int(optimal_steps),len(observations[index]))):
         obs = observations[index][i]
         action = expert_agent.get_action(obs)
         if i != len(observations[index]) -1:
            demo.append((obs, action, 0, False))
         else:
            demo.append((obs, action, 0, True))
        expert_agent._initialize_memory()

    new_demos.append(demo)

   return new_demos

# Function to check the unique number of starting observations currently present in the dataset
def find_unique_demos(demos):
   first_obs = []
   for demo in demos:
    item = copy.deepcopy(demo[0][0])
    item["image"] = item["image"].tolist()
    first_obs.append(item)
   assert len(first_obs) == len(demos)
   unique_obs = []
   for obs in first_obs:
    if obs not in unique_obs:
     unique_obs.append(obs)
   return len(unique_obs)

# Flattens the demos in a single list
def flatten(demos):
   flat_demos = []
   for demo in demos:
     flat_demos.extend(demo)
   return np.array(flat_demos)

def find_optimal_steps():
    model = args.model
    args.model = args.expert_model
    env = gym.make(args.env)
    args.deterministic = True
    expert_agent = utils.load_agent(args, env)
    env.seed(args.seed)
    utils.seed(args.seed)
    logs = evaluate(expert_agent, env, 1000)
    args.model = model
    return np.mean(logs["num_frames_per_episode"])


def main(args):
   args.episodes = 5000
   args.model = "{}_demos_{}".format(model_name, start_demo)
   il_learn = ImitationLearning(args)
   # Define logger
   logger = utils.get_logger(il_learn.model_name)

   # Log command, availability of CUDA, and model
   logger.info(args)
   logger.info("CUDA available: {}".format(torch.cuda.is_available()))
   logger.info(il_learn.acmodel)

   # Starting with start_demo number of demonstrations
   train_demos = il_learn.train_demos[:start_demo]


   while len(train_demos) < args.max_demo:

     print("Number of unique demos  is %d out of %d demos" % (find_unique_demos(train_demos), len(train_demos)))

     # Initialize a new writer
     writer = None
     if args.tb:
       from tensorboardX import SummaryWriter
       writer = SummaryWriter(utils.get_log_dir(il_learn.model_name+"_"+str(len(train_demos))))

     print("Training for %d demos" % len(train_demos))


     if args.no_mem:
        flat_train_demos = flatten(train_demos)

     # Training on the present dataset
     if not args.no_mem:
        il_learn.train(train_demos, logger, writer)
     else:
        il_learn.train(flat_train_demos, logger, writer)


     if torch.cuda.is_available():
        il_learn.acmodel.cpu()
        il_learn.device = torch.device("cpu")

     # Adding new demonstrations
     train_demos = train_demos + add_new_demos(args, il_learn)

     if torch.cuda.is_available():
       il_learn.acmodel.cuda()
       il_learn.device = torch.device("cuda")

     # Reinitializing the ImitationLearning object with a model from scratch
     args.model = "{}_demos_{}".format(model_name, len(train_demos))
     il_learn = ImitationLearning(args)
     logger = utils.get_logger(il_learn.model_name)
     logger.info(il_learn.acmodel)

if __name__ == "__main__":
  args = parser.parse_args()

  if args.dagger:
    assert args.expert_model is not None, "--expert-model not specified"
    optimal_steps = find_optimal_steps()
    print("Optimal number of steps %d" % optimal_steps)

  start_demo = args.start_demo
  batch_size = args.batch_size
  model_name = args.model

  main(args)
